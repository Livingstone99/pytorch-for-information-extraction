<!doctype html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-alpha.66">
<title data-react-helmet="true">Detection Module | Pytorch For Information Extraction</title><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" name="docusaurus_language" content="en"><meta data-react-helmet="true" name="docusaurus_version" content="current"><meta data-react-helmet="true" name="docusaurus_tag" content="docs-default-current"><meta data-react-helmet="true" property="og:title" content="Detection Module | Pytorch For Information Extraction"><meta data-react-helmet="true" name="description" content="To localize student-id(s) in images, we gonna fine-tune the state of art object segmentation algorithm Mask R-CNN  on top of pre-trained ResNet-50 available in torchvision models repository."><meta data-react-helmet="true" property="og:description" content="To localize student-id(s) in images, we gonna fine-tune the state of art object segmentation algorithm Mask R-CNN  on top of pre-trained ResNet-50 available in torchvision models repository."><meta data-react-helmet="true" property="og:url" content="https://mbassijaphet.github.io/pytorch-for-information-extraction//pytorch-for-information-extraction/detection-module"><link data-react-helmet="true" rel="shortcut icon" href="/pytorch-for-information-extraction/img/favicon.ico"><link data-react-helmet="true" rel="canonical" href="https://mbassijaphet.github.io/pytorch-for-information-extraction//pytorch-for-information-extraction/detection-module"><link rel="stylesheet" href="/pytorch-for-information-extraction/styles.3891f3db.css">
<link rel="preload" href="/pytorch-for-information-extraction/styles.bca2cbc6.js" as="script">
<link rel="preload" href="/pytorch-for-information-extraction/runtime~main.c5aed659.js" as="script">
<link rel="preload" href="/pytorch-for-information-extraction/main.fed981a0.js" as="script">
<link rel="preload" href="/pytorch-for-information-extraction/1.10db5ad8.js" as="script">
<link rel="preload" href="/pytorch-for-information-extraction/2.a4aec572.js" as="script">
<link rel="preload" href="/pytorch-for-information-extraction/17.cef2437d.js" as="script">
<link rel="preload" href="/pytorch-for-information-extraction/18.09f2fe56.js" as="script">
<link rel="preload" href="/pytorch-for-information-extraction/f976f453.5d9f15f5.js" as="script">
<link rel="preload" href="/pytorch-for-information-extraction/17896441.6e0c4643.js" as="script">
<link rel="preload" href="/pytorch-for-information-extraction/3.6b088b77.js" as="script">
<link rel="preload" href="/pytorch-for-information-extraction/e04de8e4.c07df02e.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><div aria-label="Navigation bar toggle" class="navbar__toggle" role="button" tabindex="0"><svg xmlns="http://www.w3.org/2000/svg" width="30" height="30" viewBox="0 0 30 30" role="img" focusable="false"><title>Menu</title><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></div><a class="navbar__brand" href="/pytorch-for-information-extraction/"><img class="navbar__logo" src="/pytorch-for-information-extraction/img/logo.svg" alt="My Site Logo"><strong class="navbar__title">Pytorch For Information Extraction</strong></a></div><div class="navbar__items navbar__items--right"><a aria-current="page" class="navbar__item navbar__link demo-button navbar__link--active" href="/pytorch-for-information-extraction/">Demo</a><div class="react-toggle react-toggle--disabled displayOnlyInLargeViewport_2aTZ"><div class="react-toggle-track"><div class="react-toggle-track-check"><span class="toggle_BsTx">ðŸŒœ</span></div><div class="react-toggle-track-x"><span class="toggle_BsTx">ðŸŒž</span></div></div><div class="react-toggle-thumb"></div><input type="checkbox" disabled="" aria-label="Dark mode toggle" class="react-toggle-screenreader-only"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div><div class="navbar-sidebar"><div class="navbar-sidebar__brand"><a class="navbar__brand" href="/pytorch-for-information-extraction/"><img class="navbar__logo" src="/pytorch-for-information-extraction/img/logo.svg" alt="My Site Logo"><strong class="navbar__title">Pytorch For Information Extraction</strong></a></div><div class="navbar-sidebar__items"><div class="menu"><ul class="menu__list"><li class="menu__list-item"><a aria-current="page" class="menu__link demo-button navbar__link--active" href="/pytorch-for-information-extraction/">Demo</a></li></ul></div></div></div></nav><div class="main-wrapper"><div class="docPage_2gpo"><div class="docSidebarContainer_3_JD" role="complementary"><div class="sidebar_2urC"><div class="menu menu--responsive menu_5FrY"><button aria-label="Open Menu" aria-haspopup="true" class="button button--secondary button--sm menu__button" type="button"><svg aria-label="Menu" class="sidebarMenuIcon_Dm3K" xmlns="http://www.w3.org/2000/svg" height="24" width="24" viewBox="0 0 32 32" role="img" focusable="false"><title>Menu</title><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" href="/pytorch-for-information-extraction/introduction">Getting Started</a></li><li class="menu__list-item"><a class="menu__link menu__link--sublist menu__link--active" href="#!">Modules</a><ul class="menu__list"><li class="menu__list-item"><a aria-current="page" class="menu__link menu__link--active active" tabindex="0" href="/pytorch-for-information-extraction/detection-module">1. Detection</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/pytorch-for-information-extraction/orientation-module">2. Orientation</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/pytorch-for-information-extraction/extraction-module">3. Extraction</a></li></ul></li><li class="menu__list-item"><a class="menu__link" href="/pytorch-for-information-extraction/conclusion/">Conclusion</a></li></ul></div></div></div><main class="docMainContainer_3EyW"><div class="container padding-vert--lg docItemWrapper_1EkI"><div class="row"><div class="col docItemCol_2ASc"><div class="docItemContainer_3QWW"><article><header><h1 class="docTitle_1Lrw">Detection Module</h1></header><div class="markdown"><p>To localize student-id(s) in images, we gonna fine-tune the state of art object segmentation algorithm <strong>Mask R-CNN</strong>  on top of pre-trained <a href="https://arxiv.org/abs/1703.06870" target="_blank" rel="noopener noreferrer"><strong>ResNet-50</strong></a> available in <a href="https://pytorch.org/docs/stable/torchvision/models.html#mask-r-cnn" target="_blank" rel="noopener noreferrer">torchvision</a> models repository.</p><p>So, let&#x27;s resolve the imports of our detection module.</p><pre style="display:block;overflow-x:auto;padding:0.5em;color:#abb2bf;background:#282c34;border-radius:8px;font-size:0.67em;overflow:auto;max-height:75vh"><code style="color:#e0e0e0;white-space:pre"></code></pre><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="11-detection-dataset"></a><strong>1.1. Detection Dataset</strong><a aria-hidden="true" tabindex="-1" class="hash-link" href="#11-detection-dataset" title="Direct link to heading">#</a></h2><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="111-define-dataset-class"></a>1.1.1. Define dataset class<a aria-hidden="true" tabindex="-1" class="hash-link" href="#111-define-dataset-class" title="Direct link to heading">#</a></h3><p>Recall from the <a href="/pytorch-for-information-extraction/introduction/#project-description/">project description</a> that we shall train our detection model on the <a href="https://github.com/MbassiJaphet/pytorch-for-information-extraction/tree/master/code/datasets/detection" target="_blank" rel="noopener noreferrer"><strong>Student-ID</strong></a> dataset. So letâ€™s examine its format !</p><p>A crucial requirement when fine-tuning, training, or inferencing models in Pytorch is to know the exact formats of data that specific models expect as inputs and compute as outputs.
<img alt="img" src="/pytorch-for-information-extraction/assets/images/detection-datasets-66bcf358dca91491b78492a44e010a0f.svg">
Now, knowing the formats of the Student-ID dataset as well as formats of inputs and outputs of Mask R-CNN, we can confidently code a custom dataset class inheriting from <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset" target="_blank" rel="noopener noreferrer">torch.utils.data.Dataset</a>.</p><pre style="display:block;overflow-x:auto;padding:0.5em;color:#abb2bf;background:#282c34;border-radius:8px;font-size:0.67em;overflow:auto;max-height:75vh"><code style="color:#e0e0e0;white-space:pre"></code></pre><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="112-define-transforms-for-detection-dataset"></a>1.1.2. Define transforms for detection dataset<a aria-hidden="true" tabindex="-1" class="hash-link" href="#112-define-transforms-for-detection-dataset" title="Direct link to heading">#</a></h3><p>Let&#x27;s write some helper functions for data augmentation.</p><pre style="display:block;overflow-x:auto;padding:0.5em;color:#abb2bf;background:#282c34;border-radius:8px;font-size:0.67em;overflow:auto;max-height:75vh"><code style="color:#e0e0e0;white-space:pre"></code></pre><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="113-instantiate-detection-datasets"></a>1.1.3. Instantiate detection datasets<a aria-hidden="true" tabindex="-1" class="hash-link" href="#113-instantiate-detection-datasets" title="Direct link to heading">#</a></h3><pre style="display:block;overflow-x:auto;padding:0.5em;color:#abb2bf;background:#282c34;border-radius:8px;font-size:0.67em;overflow:auto;max-height:75vh"><code style="color:#e0e0e0;white-space:pre"></code></pre><p>Just checking the names and number of classes from our detection dataset to make sure everything is <strong>OK</strong>!</p><pre style="display:block;overflow-x:auto;padding:0.5em;color:#abb2bf;background:#282c34;border-radius:8px;font-size:0.67em;overflow:auto;max-height:75vh"><code style="color:#e0e0e0;white-space:pre"></code></pre><pre class="output-block"><code></code></pre><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="114-visualize-detection-dataset"></a>1.1.4. Visualize detection dataset<a aria-hidden="true" tabindex="-1" class="hash-link" href="#114-visualize-detection-dataset" title="Direct link to heading">#</a></h3><pre style="display:block;overflow-x:auto;padding:0.5em;color:#abb2bf;background:#282c34;border-radius:8px;font-size:0.67em;overflow:auto;max-height:75vh"><code style="color:#e0e0e0;white-space:pre"></code></pre><p><img alt="img" src="/pytorch-for-information-extraction/assets/images/detection-sample-2297f873c30fffa91d665d132959c6b2.svg"></p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="12-detection-model"></a><strong>1.2. Detection Model</strong><a aria-hidden="true" tabindex="-1" class="hash-link" href="#12-detection-model" title="Direct link to heading">#</a></h2><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="121-define-detection-model"></a>1.2.1. Define detection model<a aria-hidden="true" tabindex="-1" class="hash-link" href="#121-define-detection-model" title="Direct link to heading">#</a></h3><p>Let&#x27;s define a helper function to instantiate the detection model !</p><pre style="display:block;overflow-x:auto;padding:0.5em;color:#abb2bf;background:#282c34;border-radius:8px;font-size:0.67em;overflow:auto;max-height:75vh"><code style="color:#e0e0e0;white-space:pre"></code></pre><blockquote><p><strong>Remark:</strong> The helper function above allows us to fine-tune the pre-trained <strong>FastRCNNPredictor</strong> and <strong>MaskRCNNPredictor</strong> with the desired number of classes, which are <strong>&#x27;2&#x27;</strong> in our case i.e. for the &#x27;BACKGROUND&#x27; and &#x27;Student_ID&#x27; classes.\
The function also sets the number of hidden layers of <strong>MaskRCNNPredictor</strong> to <strong>&#x27;256&#x27;</strong> but we can decide to tweak that for the best of our model performance.</p></blockquote><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="122-specify-checkpoints-and-instantiate-model"></a>1.2.2. Specify checkpoints and instantiate model<a aria-hidden="true" tabindex="-1" class="hash-link" href="#122-specify-checkpoints-and-instantiate-model" title="Direct link to heading">#</a></h3><p>Looking forward to <strong>resumable</strong> training and saving of our detection model, we shall now specify the checkpoints for the <strong>state dictionaries</strong> of the model and its training optimizer.</p><pre style="display:block;overflow-x:auto;padding:0.5em;color:#abb2bf;background:#282c34;border-radius:8px;font-size:0.67em;overflow:auto;max-height:75vh"><code style="color:#e0e0e0;white-space:pre"></code></pre><pre class="output-block"><code></code></pre><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="13-training-and-evaluation"></a><strong>1.3. Training and Evaluation</strong><a aria-hidden="true" tabindex="-1" class="hash-link" href="#13-training-and-evaluation" title="Direct link to heading">#</a></h2><p>Note that the files used for training and validation of detection module found <code>./modules/detection/scripts</code> folder were directly copied along with their dependencies from torchvision reference detection training scripts repository.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="131-specify-data-loaders"></a>1.3.1. Specify data loaders<a aria-hidden="true" tabindex="-1" class="hash-link" href="#131-specify-data-loaders" title="Direct link to heading">#</a></h3><p>After initializing the various detection datasets, let us use them to specify data loaders which shall be used for training, validation, and testing.</p><pre style="display:block;overflow-x:auto;padding:0.5em;color:#abb2bf;background:#282c34;border-radius:8px;font-size:0.67em;overflow:auto;max-height:75vh"><code style="color:#e0e0e0;white-space:pre"></code></pre><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="132-initialize-optimizer"></a>1.3.2. Initialize optimizer<a aria-hidden="true" tabindex="-1" class="hash-link" href="#132-initialize-optimizer" title="Direct link to heading">#</a></h3><p>Let&#x27;s initialize the optimizer for training the detection model, and get ready for training !</p><pre style="display:block;overflow-x:auto;padding:0.5em;color:#abb2bf;background:#282c34;border-radius:8px;font-size:0.67em;overflow:auto;max-height:75vh"><code style="color:#e0e0e0;white-space:pre"></code></pre><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="133-define-training-function"></a>1.3.3. Define training function<a aria-hidden="true" tabindex="-1" class="hash-link" href="#133-define-training-function" title="Direct link to heading">#</a></h3><p>Now, let&#x27;s write the function that will train and validate our model for us. Inside the training function, we shall add a few lines of code that will save our model checkpoints.</p><pre style="display:block;overflow-x:auto;padding:0.5em;color:#abb2bf;background:#282c34;border-radius:8px;font-size:0.67em;overflow:auto;max-height:75vh"><code style="color:#e0e0e0;white-space:pre"></code></pre><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="134-train-detection-model"></a>1.3.4 Train detection model<a aria-hidden="true" tabindex="-1" class="hash-link" href="#134-train-detection-model" title="Direct link to heading">#</a></h3><p>So letâ€™s train our detection model for 20 epochs saving it at the end of each epoch.</p><pre style="display:block;overflow-x:auto;padding:0.5em;color:#abb2bf;background:#282c34;border-radius:8px;font-size:0.67em;overflow:auto;max-height:75vh"><code style="color:#e0e0e0;white-space:pre"></code></pre><pre class="output-block"><code></code></pre><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="135-resume-training-detection-model"></a>1.3.5. Resume training detection model<a aria-hidden="true" tabindex="-1" class="hash-link" href="#135-resume-training-detection-model" title="Direct link to heading">#</a></h3><p>At the end of every epoch, we had the checkpoints of the detection module updated. Now let&#x27;s use these updated checkpoints to reload the detection model and resume its training up to <strong>&#x27;30&#x27;</strong> epochs.</p><blockquote><p><strong>IMPORTANT !!!</strong> To reload the detection model and the detection optimizer from the checkpoint, simply re-run the code cell at Section 1.2.2. and Section 1.3.2 respectively. Just make sure <code>load_detection_checkpoint</code> is set to <code>True</code>. The resulting output shall be identical to the one below.</p></blockquote><p>Reloading detection model from the checkpoint. (Section 1.2.2)</p><pre class="output-block"><code></code></pre><p>Reloading detection optimizer from the checkpoint (Section 1.3.2)</p><pre class="output-block"><code></code></pre><p>Now let&#x27;s resume training of our detection model.</p><pre style="display:block;overflow-x:auto;padding:0.5em;color:#abb2bf;background:#282c34;border-radius:8px;font-size:0.67em;overflow:auto;max-height:75vh"><code style="color:#e0e0e0;white-space:pre"></code></pre><pre class="output-block"><code></code></pre><p>You notice that the training start from epoch 21 since the detection model has already been trained for 20 epochs.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="136-evaluate-the-detection-model"></a>1.3.6. Evaluate the detection model<a aria-hidden="true" tabindex="-1" class="hash-link" href="#136-evaluate-the-detection-model" title="Direct link to heading">#</a></h3><p>To conclude on the performance of your models, it is always of good practice to evaluate them on sample data.</p><p>We shall evaluate the performance of the detection model on sample images from the testing dataset.</p><p>Firstly, let&#x27;s use our detection model to compute predictions for an input image from the test detection dataset.</p><pre style="display:block;overflow-x:auto;padding:0.5em;color:#abb2bf;background:#282c34;border-radius:8px;font-size:0.67em;overflow:auto;max-height:75vh"><code style="color:#e0e0e0;white-space:pre"></code></pre><p><img alt="img" src="/pytorch-for-information-extraction/assets/images/student-id-01-4636266652e4b32f00b75bf894324013.svg"></p><p>Secondly, let&#x27;s take a look at the raw outputs predicted by our detection model for the image above.</p><pre style="display:block;overflow-x:auto;padding:0.5em;color:#abb2bf;background:#282c34;border-radius:8px;font-size:0.67em;overflow:auto;max-height:75vh"><code style="color:#e0e0e0;white-space:pre"></code></pre><pre class="output-block"><code></code></pre><p>Lastly, let&#x27;s convert the raw predicted outputs into a human-understandable format for proper visualization.</p><pre style="display:block;overflow-x:auto;padding:0.5em;color:#abb2bf;background:#282c34;border-radius:8px;font-size:0.67em;overflow:auto;max-height:75vh"><code style="color:#e0e0e0;white-space:pre"></code></pre><p><img alt="img" src="/pytorch-for-information-extraction/assets/images/detection-prediction-140d791c826f5968ee109c7cd3661f33.svg"></p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="14-preparation-for-orientation-module"></a><strong>1.4. Preparation for Orientation Module</strong><a aria-hidden="true" tabindex="-1" class="hash-link" href="#14-preparation-for-orientation-module" title="Direct link to heading">#</a></h2><p>At the beginning of this tutorial, we&#x27;ve mentioned that the goal of the detection module was to predict the position of documents of interest (which are student-ids in our case) with-in an image, but it does more than that. The segmentation mask computed for a student-id is used to perform image alignment on its corresponding student-id. The resulting aligned image is then fed as input to the orientation module.</p><pre style="display:block;overflow-x:auto;padding:0.5em;color:#abb2bf;background:#282c34;border-radius:8px;font-size:0.67em;overflow:auto;max-height:75vh"><code style="color:#e0e0e0;white-space:pre"></code></pre><p><img alt="img" src="/pytorch-for-information-extraction/assets/images/image-alignment-0e5cbddee6adae8aff723dd8f4867986.svg"></p></div></article><div class="margin-vert--xl"><div class="row"><div class="col"><a href="https://github.com/MbassiJaphet/pytorch-for-information-extraction/edit/master/docs/detection.md" target="_blank" rel="noreferrer noopener"><svg fill="currentColor" height="1.2em" width="1.2em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 40 40" style="margin-right:0.3em;vertical-align:sub"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div></div></div><div class="margin-vert--lg"><nav class="pagination-nav" aria-label="Blog list page navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/pytorch-for-information-extraction/introduction"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Â« Getting Started</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/pytorch-for-information-extraction/orientation-module"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Orientation Module Â»</div></a></div></nav></div></div></div><div class="col col--3"><div class="tableOfContents_3SO_"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#11-detection-dataset" class="table-of-contents__link"><strong>1.1. Detection Dataset</strong></a><ul><li><a href="#111-define-dataset-class" class="table-of-contents__link">1.1.1. Define dataset class</a></li><li><a href="#112-define-transforms-for-detection-dataset" class="table-of-contents__link">1.1.2. Define transforms for detection dataset</a></li><li><a href="#113-instantiate-detection-datasets" class="table-of-contents__link">1.1.3. Instantiate detection datasets</a></li><li><a href="#114-visualize-detection-dataset" class="table-of-contents__link">1.1.4. Visualize detection dataset</a></li></ul></li><li><a href="#12-detection-model" class="table-of-contents__link"><strong>1.2. Detection Model</strong></a><ul><li><a href="#121-define-detection-model" class="table-of-contents__link">1.2.1. Define detection model</a></li><li><a href="#122-specify-checkpoints-and-instantiate-model" class="table-of-contents__link">1.2.2. Specify checkpoints and instantiate model</a></li></ul></li><li><a href="#13-training-and-evaluation" class="table-of-contents__link"><strong>1.3. Training and Evaluation</strong></a><ul><li><a href="#131-specify-data-loaders" class="table-of-contents__link">1.3.1. Specify data loaders</a></li><li><a href="#132-initialize-optimizer" class="table-of-contents__link">1.3.2. Initialize optimizer</a></li><li><a href="#133-define-training-function" class="table-of-contents__link">1.3.3. Define training function</a></li><li><a href="#134-train-detection-model" class="table-of-contents__link">1.3.4 Train detection model</a></li><li><a href="#135-resume-training-detection-model" class="table-of-contents__link">1.3.5. Resume training detection model</a></li><li><a href="#136-evaluate-the-detection-model" class="table-of-contents__link">1.3.6. Evaluate the detection model</a></li></ul></li><li><a href="#14-preparation-for-orientation-module" class="table-of-contents__link"><strong>1.4. Preparation for Orientation Module</strong></a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container"><div class="row footer__links"><div class="col footer__col"><h4 class="footer__title">Get Started</h4><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/pytorch-for-information-extraction/introduction">Style Guide</a></li></ul></div><div class="col footer__col"><h4 class="footer__title">Community</h4><ul class="footer__items"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/pytorch-for-information-extraction" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow</a></li></ul></div><div class="col footer__col"><h4 class="footer__title">More</h4><ul class="footer__items"><li class="footer__item"><a href="https://github.com/MbassiJaphet/pytorch-for-information-extraction" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub</a></li></ul></div></div><div class="text--center"><div>Copyright Â© 2020 Pytorch For Information Extraction. Built with Docusaurus.</div></div></div></footer></div>
<script src="/pytorch-for-information-extraction/styles.bca2cbc6.js"></script>
<script src="/pytorch-for-information-extraction/runtime~main.c5aed659.js"></script>
<script src="/pytorch-for-information-extraction/main.fed981a0.js"></script>
<script src="/pytorch-for-information-extraction/1.10db5ad8.js"></script>
<script src="/pytorch-for-information-extraction/2.a4aec572.js"></script>
<script src="/pytorch-for-information-extraction/17.cef2437d.js"></script>
<script src="/pytorch-for-information-extraction/18.09f2fe56.js"></script>
<script src="/pytorch-for-information-extraction/f976f453.5d9f15f5.js"></script>
<script src="/pytorch-for-information-extraction/17896441.6e0c4643.js"></script>
<script src="/pytorch-for-information-extraction/3.6b088b77.js"></script>
<script src="/pytorch-for-information-extraction/e04de8e4.c07df02e.js"></script>
</body>
</html>