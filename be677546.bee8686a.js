(window.webpackJsonp=window.webpackJsonp||[]).push([[11],{334:function(t,e,i){"use strict";i.r(e),e.default=i.p+"assets/images/fields-coordinates-hypothesis-acc032f98b5f36165d69072452e4570e.svg"},335:function(t,e,i){"use strict";i.r(e),e.default=i.p+"assets/images/fields-coordinates-d0ddea26d07fce1b5714c89a5985f7c0.svg"},336:function(t,e,i){"use strict";i.r(e),e.default=i.p+"assets/images/extraction-prediction-dd36e7747352dabed4376273fda1b13e.svg"},66:function(t,e,i){"use strict";i.r(e),i.d(e,"frontMatter",(function(){return c})),i.d(e,"metadata",(function(){return l})),i.d(e,"rightToc",(function(){return d})),i.d(e,"default",(function(){return h}));var n=i(2),o=i(6),r=(i(0),i(73)),a=i(83),s=i(80),c={id:"extraction",sidebar_label:"3. Extraction",title:"Extraction Module",slug:"/extraction-module"},l={unversionedId:"extraction",id:"extraction",isDocsHomePage:!1,title:"Extraction Module",description:"We started from the detection of student-id(s) followed by the correction of their orientations and now we have finally reached the extraction module. Once more we shall recall that this final module which puts an end to our Information Extraction pipeline aims at extracting information from fields within student-id(s). In this sense, we shall now ask ourselves how to individually extract the fields within student-id(s) which are of interest to us ? The answer to that question is quite simple and is nothing Pytorch related.",source:"@site/docs/extraction.md",slug:"/extraction-module",permalink:"/pytorch-for-information-extraction/extraction-module",editUrl:"https://github.com/MbassiJaphet/pytorch-for-information-extraction/edit/master/docs/extraction.md",version:"current",sidebar_label:"3. Extraction",sidebar:"tutorial",previous:{title:"Orientation Module",permalink:"/pytorch-for-information-extraction/orientation-module"},next:{title:"Tutorial Conclusion",permalink:"/pytorch-for-information-extraction/conclusion/"}},d=[{value:"3.1 Fields Coordinates Hypothesis",id:"31-fields-coordinates-hypothesis",children:[]},{value:"3.2 Student-ID Fields Coordinates",id:"32-student-id-fields-coordinates",children:[]},{value:"3.3 Extract Fields and/or Information",id:"33-extract-fields-andor-information",children:[]}],u={rightToc:d};function h(t){var e=t.components,c=Object(o.a)(t,["components"]);return Object(r.b)("wrapper",Object(n.a)({},u,c,{components:e,mdxType:"MDXLayout"}),Object(r.b)("p",null,"We started from the detection of student-id(s) followed by the correction of their orientations and now we have finally reached the extraction module. Once more we shall recall that this final module which puts an end to our Information Extraction pipeline aims at extracting information from fields within student-id(s). In this sense, we shall now ask ourselves how to individually extract the fields within student-id(s) which are of interest to us ? The answer to that question is quite simple and is nothing Pytorch related."),Object(r.b)("h2",{id:"31-fields-coordinates-hypothesis"},"3.1 Fields Coordinates Hypothesis"),Object(r.b)("p",null,"For an individual field, we shall use the coordinates of the size of a student id. The image below better illustrates our hypothesis.\n",Object(r.b)("img",{alt:"img",src:i(334).default})),Object(r.b)("p",null,"From the image above, the aspect ratio of a field with respect to the size of a fixed-sized document remains constant no matter the size of the image document."),Object(r.b)("h2",{id:"32-student-id-fields-coordinates"},"3.2 Student-ID Fields Coordinates"),Object(r.b)("p",null,"Below is a figure illustrating how we shall implement the above hypothesis. The figure also pinpoints specific fields we shall try extract following our hypothesis."),Object(r.b)("p",null,Object(r.b)("img",{alt:"img",src:i(335).default})),Object(r.b)("p",null,"The coordinates of each of the above-illustrated were extrapolated prior to this module and stored in the ",Object(r.b)("inlineCode",{parentName:"p"},"field_coordiinates.yaml")," file. Consequently,  shall use these coordinates to extract fields containing meaningful information, from aligned documents to effectuate information extraction."),Object(r.b)("p",null,"Let's load the and print out fields' coordinates."),Object(r.b)(a.a,{file:"extraction_coordinates_init",mdxType:"CodeBlock"}),Object(r.b)(s.a,{file:"extraction_coordinates_init_output",mdxType:"OutputBlock"}),Object(r.b)("h2",{id:"33-extract-fields-andor-information"},"3.3 Extract Fields and/or Information"),Object(r.b)("p",null,"Finally, let's use the fields' coordinates to extract the information fields for the aligned student-id which had its orientation corrected by the orientation module."),Object(r.b)(a.a,{file:"extraction_predictions",mdxType:"CodeBlock"}),Object(r.b)("p",null,Object(r.b)("img",{alt:"img",src:i(336).default})),Object(r.b)("p",null,"The result is pretty impressive right! At this point, graphic information might be stored as-is, but what else we can do is to use an ",Object(r.b)("a",Object(n.a)({parentName:"p"},{href:"http://www.cvisiontech.com/library/ocr/image-ocr/ocr-engines.html"}),"OCR engine")," to retrieve texts from textual fields."))}h.isMDXComponent=!0},80:function(t,e,i){"use strict";var n=i(3),o=i(0),r=i.n(o),a=function(t){function e(e){var i;return(i=t.call(this,e)||this)._currentFile=null,i.state={outputString:""},i}Object(n.a)(e,t),e.getDerivedStateFromProps=function(t,e){return t.id!==e.prevFile?{outputString:"",prevFile:t.file}:null};var i=e.prototype;return i.componentDidMount=function(){this._loadAsyncData(this.props.file)},i.componentDidUpdate=function(t,e){this.state.outputString||this._loadAsyncData(this.props.file)},i.componentWillUnmount=function(){this._currentFile=null},i.render=function(){return r.a.createElement("pre",{className:"output-block"},r.a.createElement("code",null,this.state.outputString))},i._loadAsyncData=function(t){var e=this;this._currentFile=t,fetch("/pytorch-for-information-extraction/code-snippets/"+t+".txt").then((function(t){return t.text()})).then((function(i){t===e._currentFile&&e.setState({outputString:i})})).catch((function(t){console.log(t)}))},e}(r.a.Component);e.a=a},83:function(t,e,i){"use strict";var n,o=i(3),r=i(0),a=i.n(r),s=(i(77),i(343)),c=i(342),l=function(t){function e(e){var i;return(i=t.call(this,e)||this).state={codeString:""},i._currentFile=null,i}Object(o.a)(e,t),e.getDerivedStateFromProps=function(t,e){return t.id!==e.prevFile?{codeString:"",prevFile:t.file}:null};var i=e.prototype;return i.componentDidMount=function(){this._loadAsyncData(this.props.file)},i.componentDidUpdate=function(t,e){this.state.codeString||this._loadAsyncData(this.props.file)},i.componentWillUnmount=function(){this._currentFile=null},i._highlightLine=function(t){var e={display:"block"};return this.props.lines&&this.props.lines.includes(t)&&(e.backgroundColor="rgb(144, 202, 249, 0.15)"),{style:e}},i.render=function(){return a.a.createElement("div",{class:"code-block"},a.a.createElement(s.a,{language:"python",lineProps:this._highlightLine.bind(this),wrapLines:!0,lineNumberStyle:{color:"#80d6ff"},style:c.a,showLineNumbers:!0,customStyle:d,codeTagProps:{style:{color:"#e0e0e0"}}},this.state.codeString))},i._loadAsyncData=function(t){var e=this;this._currentFile=t,fetch("/pytorch-for-information-extraction/code-snippets/"+t+".py").then((function(t){return t.text()})).then((function(i){t===e._currentFile&&e.setState({codeString:i})})).catch((function(t){console.log(t)}))},e}(a.a.Component);e.a=l;var d=((n={borderRadius:0,overflow:"auto",maxHeight:"75vh",fontSize:"0.67em"}).borderRadius=8,n)}}]);